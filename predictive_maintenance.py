# -*- coding: utf-8 -*-
"""predictive_maintenance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HE-rx-_NUBodC1JRGo24gcKOnnc_NdAi
"""

# Neccesary Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
sns.set_style('whitegrid')

# Loading Dataset
file_path = './machine_failure_dataset.csv'
df = pd.read_csv(file_path)
df.head()

df.describe().T

# Check for Null Values
df.isnull().sum()

# Check of type
df.info()

print('-'*50)
# Encode Machine_Type
df.Machine_Type.value_counts()

# One Hot Encoding
df = pd.get_dummies(df,columns = ['Machine_Type'],drop_first = True)

print('-'*50)

df.head()

cols = df.columns

cols

# Plot Data Distributions
for col in df.columns:
    sns.histplot(df[col],kde = True)
    plt.show()

cols

def check_outliers(col, df):
    """
    desc : Identifies outliers in a specified column of a DataFrame using the IQR method.
    i/p  : col <str> - Column Name, df <DataFrame> - Dataset
    o/p  : DataFrame with outliers and a summary of outliers
    """

    # Before
    sns.boxplot(df[col])
    plt.title(col + ' Box Plot')
    plt.show()

    # Outlier Present ?
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    pos_t = Q3 + 1.5 * IQR
    neg_t = Q1 - 1.5 * IQR

    outliers = df[(df[col] < neg_t) | (df[col] > pos_t)]

    if len(outliers) == 0:
        status = 'No'
    else:
        status = 'Yes'

    outlier_summary = {
        'Present': status,
        'Lower Bound': neg_t,
        'Upper Bound': pos_t,
        'Number Of Outliers' : outliers.shape[0]
    }

    if status == 'Yes':
        df.drop(outliers.index, inplace=True)
        # After dropping outliers
        sns.boxplot(df[col])
        plt.title(col + ' Box Plot (After Outlier Treatment)')
        plt.show()

    return outlier_summary, df

df.columns[:]

for col in df.columns[0:5]:
    outlier_summary, df = check_outliers(col, df)
    print(outlier_summary)
    print('-'*50)

df.head()

df.describe().T

X = df.drop(['Failure_Risk'],axis = 1)
y = df.Failure_Risk

# Scale the data

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Split Build Evaluate

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Make predictions
y_pred_log_reg = log_reg.predict(X_test)

# Evaluate model
print("Logistic Regression")
print("Accuracy:", accuracy_score(y_test, y_pred_log_reg))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_log_reg))
print("Classification Report:\n", classification_report(y_test, y_pred_log_reg))

# Train model
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Make predictions
y_pred_knn = knn.predict(X_test)

# Evaluate model
print("K-Nearest Neighbors")
print("Accuracy:", accuracy_score(y_test, y_pred_knn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_knn))
print("Classification Report:\n", classification_report(y_test, y_pred_knn))

# Train model
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)

# Make predictions
y_pred_svm = svm.predict(X_test)

# Evaluate model
print("Support Vector Machine")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_svm))
print("Classification Report:\n", classification_report(y_test, y_pred_svm))

# Train model
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)

# Make predictions
y_pred_svm = svm.predict(X_test)

# Evaluate model
print("Support Vector Machine")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_svm))
print("Classification Report:\n", classification_report(y_test, y_pred_svm))

# Train model
random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train, y_train)

# Make predictions
y_pred_random_forest = random_forest.predict(X_test)

# Evaluate model
print("Random Forest")
print("Accuracy:", accuracy_score(y_test, y_pred_random_forest))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_random_forest))
print("Classification Report:\n", classification_report(y_test, y_pred_random_forest))

